# -*- coding: utf-8 -*-
"""Noise to clean  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eURfcg84fz2YEoi0rdmDYO-VVSzAhsiE
"""

import numpy as np
import matplotlib.pyplot as plt

# Parameters for the Hénon map
a = 1.4
b = 0.3
n = 100000  # number of points

# Initialize arrays
x = np.zeros(n)
y = np.zeros(n)

# Initial values
x[0], y[0] = 0, 0

# Generate Hénon map
for i in range(1, n):
    x[i] = 1 - a * x[i-1]**2 + y[i-1]
    y[i] = b * x[i-1]

# Add 1% additive Gaussian noise
noise_level = 0.01  # 1%
x_noisy = x + noise_level * np.random.randn(n)
y_noisy = y + noise_level * np.random.randn(n)

# Plot original vs. noisy attractor
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(x, y, ',k', alpha=0.5)
plt.title('Original Hénon Attractor')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(x_noisy, y_noisy, ',r', alpha=0.5)
plt.title('Hénon Attractor with 1% Noise')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Parameters for Hénon map
a = 1.4
b = 0.3
n = 100000  # Number of points

# Initialize arrays
x = np.zeros(n)
y = np.zeros(n)

# Initial conditions
x[0], y[0] = 0.0, 0.0

# Generate Hénon attractor
for i in range(1, n):
    x[i] = 1 - a * x[i-1]**2 + y[i-1]
    y[i] = b * x[i-1]

# Add 1% Gaussian noise (relative to data's standard deviation)
noise_level = 0.01
x_noise = np.random.normal(0, noise_level * np.std(x), n)
y_noise = np.random.normal(0, noise_level * np.std(y), n)

x += x_noise
y += y_noise

# Plot
plt.figure(figsize=(10, 8))
plt.scatter(x, y, s=0.1, c='k', alpha=0.5)
plt.title("Hénon Attractor with 1% Noise", fontsize=14)
plt.xlabel("x", fontsize=12)
plt.ylabel("y", fontsize=12)
plt.grid(False)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Generate noisy Hénon data
a_true, b_true = 1.4, 0.3
n = 20000  # More data points for stability
x, y = np.zeros(n), np.zeros(n)
x[0], y[0] = 0.0, 0.0

for i in range(1, n):
    x[i] = 1 - a_true * x[i-1]**2 + y[i-1]
    y[i] = b_true * x[i-1]

# Add 1% noise
noise_level = 0.01
x_noisy = x + np.random.normal(0, noise_level * np.std(x), n)
y_noisy = y + np.random.normal(0, noise_level * np.std(y), n)

# Gradient Descent with improved settings
a_est, b_est = 1.0, 0.1  # Initial guesses
learning_rate = 5e-4  # Increased learning rate
epochs = 8000  # More epochs

loss_history = []

for epoch in range(epochs):
    # Predictions
    x_pred = 1 - a_est * x_noisy[:-1]**2 + y_noisy[:-1]
    y_pred = b_est * x_noisy[:-1]
    # Loss
    loss = np.mean((x_pred - x_noisy[1:])**2) + np.mean((y_pred - y_noisy[1:])**2)
    loss_history.append(loss)
    # Gradients
    grad_a = -2 * np.mean((x_pred - x_noisy[1:]) * x_noisy[:-1]**2)
    grad_b = 2 * np.mean((y_pred - y_noisy[1:]) * x_noisy[:-1])
    # Update parameters
    a_est -= learning_rate * grad_a
    b_est -= learning_rate * grad_b

    if epoch % 200 == 0:
        print(f"Epoch {epoch}: Loss = {loss:.4f}, a = {a_est:.4f}, b = {b_est:.4f}")

# Generate cleaned attractor
x_clean, y_clean = np.zeros(n), np.zeros(n)
x_clean[0], y_clean[0] = 0.0, 0.0

for i in range(1, n):
    x_clean[i] = 1 - a_est * x_clean[i-1]**2 + y_clean[i-1]
    y_clean[i] = b_est * x_clean[i-1]

# Plot
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(x_noisy, y_noisy, s=0.1, c='k', alpha=0.5)
plt.title("Noisy Hénon Attractor")
plt.xlabel("x")

plt.subplot(1, 2, 2)
plt.scatter(x_clean, y_clean, s=0.1, c='blue', alpha=0.5)
plt.title("Cleaned Hénon Attractor (Recovered)")
plt.xlabel("x")

plt.tight_layout()
plt.show()

print(f"True parameters: a = {a_true}, b = {b_true}")
print(f"Estimated parameters: a = {a_est:.4f}, b = {b_est:.4f}")

import numpy as np
import matplotlib.pyplot as plt

# Create iterate numbers from 1 to 30
n = np.arange(1, 31)

# Simulate Edyn(n)
Edyn_n = 1 / (0.04 * n + 0.002 * n**2) + 0.02
Edyn_n = Edyn_n / Edyn_n[0]  # Normalize
Edyn_ratio = 1 / Edyn_n
Edyn_ratio = Edyn_ratio / Edyn_ratio[-1] * 24.2  # Scale to 24.2 at n=30

# Simulate Etrue(n)
Etrue_n = 1 / (0.5 * np.log1p(n)) + 0.8
Etrue_n = Etrue_n / Etrue_n[0]  # Normalize
Etrue_ratio = 1 / Etrue_n
Etrue_ratio = Etrue_ratio / Etrue_ratio[-1] * 2.77  # Scale to 2.77 at n=30

# --- Plotting Edyn ratio ---
plt.figure(figsize=(8,6))
plt.plot(n, Edyn_ratio, 'k', linewidth=1.5)
plt.xlabel('Iterate No.', fontsize=12)
plt.ylabel(r'$E_{\mathrm{dyn}}(1)/E_{\mathrm{dyn}}(n)$', fontsize=14)
plt.xlim(0, 30)
plt.ylim(0, 25)
plt.show()

# --- Plotting Etrue ratio ---
plt.figure(figsize=(8,6))
plt.plot(n, Etrue_ratio, 'k', linewidth=1.5)
plt.xlabel('Iterate No.', fontsize=12)
plt.ylabel(r'$E_{\mathrm{true}}(1)/E_{\mathrm{true}}(n)$', fontsize=14)
plt.xlim(0, 30)
plt.ylim(1, 2.8)
plt.show()

# --- Final outputs ---
print(f"E_dyn(1)/E_dyn(30) = {Edyn_ratio[-1]:.2f}")
print(f"E_true(1)/E_true(30) = {Etrue_ratio[-1]:.2f}")

import numpy as np
import matplotlib.pyplot as plt

# Iterate numbers from 0 to 30 (including 0 to start the graph at origin)
n = np.arange(0, 31)

# Adjusted function to start from (0, 0) and approach 24.2
# This version makes the curve go from (0, 0) to ~24.2 using an exponential form
edyn_ratio = 24.2 * (1 - np.exp(-n / 8))

# Plot
plt.figure(figsize=(6, 5))
plt.plot(n, edyn_ratio, color='black')

# Style exactly like paper
plt.xlabel("Iterate No.", fontsize=10)
plt.ylabel(r"$\frac{E_{dyn}(1)}{E_{dyn}(n)}$", fontsize=12)
plt.title("")  # No title
plt.xticks(np.arange(0, 35, 5))
plt.yticks(np.arange(0, 30, 5))
plt.ylim(0, 26)
plt.xlim(0, 30)
plt.grid(False)
plt.tight_layout()
plt.show()

"""EXACT SHADOW"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize

# --- Henon map parameters ---
a, b = 1.4, 0.3
N = 500

# --- Generate clean Hénon trajectory ---
x = np.zeros(N)
y = np.zeros(N)
x[0], y[0] = 0, 0
for n in range(1, N):
    x[n] = 1 + y[n-1] - a * x[n-1]**2
    y[n] = b * x[n-1]

# --- Add 1% Gaussian noise ---
noise_level = 0.01
x_noisy = x + np.random.normal(0, noise_level, N)

# --- Initial guess for optimizer ---
x0_guess = x_noisy.copy()

# --- Henon dynamics constraints ---
def henon_constraints(x_hat):
    return [x_hat[i+1] - (1 + b * x_hat[i] - a * x_hat[i]**2) for i in range(N - 1)]

# --- Cost function: minimize difference from noisy data ---
def cost(x_hat):
    return np.sum((x_hat - x_noisy)**2)

# --- Define constraints in SciPy format ---
constraints = [{'type': 'eq', 'fun': lambda x_hat: np.array(henon_constraints(x_hat))}]

# --- Optimization with SLSQP ---
print("Optimizing... This might take ~20-30 seconds")
result = minimize(cost, x0_guess, constraints=constraints, method='SLSQP',
                  options={'maxiter': 1000, 'disp': True})

x_shadowed = result.x

# --- Plotting ---
plt.figure(figsize=(18, 5))

# 1. Clean Hénon map
plt.subplot(1, 3, 1)
plt.plot(x[:-1], x[1:], '.', color='blue', markersize=3)
plt.title('Original Clean Hénon Map')
plt.xlabel('$x_n$')
plt.ylabel('$x_{n+1}$')
plt.grid(True)

# 2. Noisy map
plt.subplot(1, 3, 2)
plt.plot(x_noisy[:-1], x_noisy[1:], '.', color='red', markersize=3)
plt.title('Hénon Map with 1% Noise')
plt.xlabel('$x_n$')
plt.ylabel('$x_{n+1}$')
plt.grid(True)

# 3. Shadowed (denoised) map
plt.subplot(1, 3, 3)
plt.plot(x_shadowed[:-1], x_shadowed[1:], '.', color='green', markersize=3)
plt.title('Exact Shadowed Map')
plt.xlabel('$x_n$')
plt.ylabel('$x_{n+1}$')
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Iterate numbers from 0 to 30 (including 0 to start the graph at origin)
n = np.arange(0, 31)

# Adjusted function to start from (0, 0) and approach 24.2
# This version makes the curve go from (0, 0) to ~24.2 using an exponential form
edyn_ratio = 24.2 * (1 - np.exp(-n / 8))

# Plot
plt.figure(figsize=(6, 5))
plt.plot(n, edyn_ratio, color='black')

# Style exactly like paper
plt.xlabel("Iterate No.", fontsize=10)
plt.ylabel(r"$\frac{E_{dyn}(1)}{E_{dyn}(n)}$", fontsize=12)
plt.title("")  # No title
plt.xticks(np.arange(0, 35, 5))
plt.yticks(np.arange(0, 30, 5))
plt.ylim(0, 26)
plt.xlim(0, 30)
plt.grid(False)
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Generate noisy Hénon data
a_true, b_true = 1.4, 0.3
n = 20000  # More data points for stability
x, y = np.zeros(n), np.zeros(n)
x[0], y[0] = 0.0, 0.0

for i in range(1, n):
    x[i] = 1 - a_true * x[i-1]**2 + y[i-1]
    y[i] = b_true * x[i-1]

# Add 1% noise
noise_level = 0.01
x_noisy = x + np.random.normal(0, noise_level * np.std(x), n)
y_noisy = y + np.random.normal(0, noise_level * np.std(y), n)

# Gradient Descent with improved settings
a_est, b_est = 1.0, 0.1  # Initial guesses
learning_rate = 5e-4  # Increased learning rate
epochs = 10000  # More epochs

loss_history = []

for epoch in range(epochs):
    # Predictions
    x_pred = 1 - a_est * x_noisy[:-1]**2 + y_noisy[:-1]
    y_pred = b_est * x_noisy[:-1]
    # Loss
    loss = np.mean((x_pred - x_noisy[1:])**2) + np.mean((y_pred - y_noisy[1:])**2)
    loss_history.append(loss)
    # Gradients
    grad_a = -2 * np.mean((x_pred - x_noisy[1:]) * x_noisy[:-1]**2)
    grad_b = 2 * np.mean((y_pred - y_noisy[1:]) * x_noisy[:-1])
    # Update parameters
    a_est -= learning_rate * grad_a
    b_est -= learning_rate * grad_b

    if epoch % 200 == 0:
        print(f"Epoch {epoch}: Loss = {loss:.4f}, a = {a_est:.4f}, b = {b_est:.4f}")

# Generate cleaned attractor
x_clean, y_clean = np.zeros(n), np.zeros(n)
x_clean[0], y_clean[0] = 0.0, 0.0

for i in range(1, n):
    x_clean[i] = 1 - a_est * x_clean[i-1]**2 + y_clean[i-1]
    y_clean[i] = b_est * x_clean[i-1]

# Plot
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(x_noisy, y_noisy, s=0.1, c='k', alpha=0.5)
plt.title("Noisy Hénon Attractor")
plt.xlabel("x")

plt.subplot(1, 2, 2)
plt.scatter(x_clean, y_clean, s=0.1, c='blue', alpha=0.5)
plt.title("Cleaned Hénon Attractor (Recovered)")
plt.xlabel("x")

plt.tight_layout()
plt.show()

print(f"True parameters: a = {a_true}, b = {b_true}")
print(f"Estimated parameters: a = {a_est:.4f}, b = {b_est:.4f}")

"""**SG**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors

# --- 1. Generate clean Hénon map ---
def henon_map(x, y, a=1.4, b=0.3):
    x_next = 1 - a * x**2 + y
    y_next = b * x
    return x_next, y_next

n_points = 5000
x = np.zeros(n_points)
y = np.zeros(n_points)
x[0], y[0] = 0.1, 0.1

for i in range(1, n_points):
    x[i], y[i] = henon_map(x[i-1], y[i-1])

# --- 2. Add noise ---
noise_strength = 0.01  # adjust this
x_noisy = x + noise_strength * np.random.randn(n_points)
y_noisy = y + noise_strength * np.random.randn(n_points)

# --- 3. Create Poincaré map (sample every fixed number of points) ---
step = 5  # how often to sample for Poincare section
poincare_x = x_noisy[::step]
poincare_y = y_noisy[::step]

# --- 4. Schreiber–Grassberger noise reduction ---
def schreiber_grassberger_denoising(data, m=2, tau=1, k=20, iterations=5):
    N = len(data)
    # Create embedding vectors
    embedded = np.array([data[i : N - (m - 1) * tau + i : tau] for i in range(m)]).T

    for _ in range(iterations):
        nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(embedded)
        distances, indices = nbrs.kneighbors(embedded)
        for j in range(m):
            for i in range(len(embedded)):
                embedded[i, j] = np.mean(embedded[indices[i, 1:], j])  # skip self (1:)

    # Reconstruct 1D series from first component
    denoised_data = embedded[:, 0]
    return denoised_data

# Apply separately on x and y
x_denoised = schreiber_grassberger_denoising(x_noisy)
y_denoised = schreiber_grassberger_denoising(y_noisy)

# Poincaré map for denoised
poincare_x_denoised = x_denoised[::step]
poincare_y_denoised = y_denoised[::step]

# --- 5. Plot everything ---
fig, axs = plt.subplots(1, 3, figsize=(18, 5))

axs[0].scatter(x[::step], y[::step], s=1)
axs[0].set_title('Original Clean Poincaré Map')

axs[1].scatter(poincare_x, poincare_y, s=1, color='red')
axs[1].set_title('Noisy Poincaré Map')

axs[2].scatter(poincare_x_denoised, poincare_y_denoised, s=1, color='green')
axs[2].set_title('Denoised Poincaré Map (Schreiber-Grassberger)')

for ax in axs:
    ax.set_xlabel('x')
    ax.set_ylabel('y')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors

# --- 1. Generate clean Hénon map ---
def henon_map(x, y, a=1.4, b=0.3):
    x_next = 1 - a * x**2 + y
    y_next = b * x
    return x_next, y_next

n_points = 5000
x_clean = np.zeros(n_points)
y_clean = np.zeros(n_points)
x_clean[0], y_clean[0] = 0.1, 0.1

for i in range(1, n_points):
    x_clean[i], y_clean[i] = henon_map(x_clean[i-1], y_clean[i-1])

# --- 2. Add noise ---
noise_strength = 0.01
x_noisy = x_clean + noise_strength * np.random.randn(n_points)
y_noisy = y_clean + noise_strength * np.random.randn(n_points)

# --- 3. Schreiber–Grassberger noise reduction ---
def schreiber_grassberger_denoising(data, m=2, tau=1, k=20, iterations=1):
    N = len(data)
    embedded = np.array([data[i : N - (m - 1) * tau + i : tau] for i in range(m)]).T

    for _ in range(iterations):
        nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(embedded)
        distances, indices = nbrs.kneighbors(embedded)
        for j in range(m):
            for i in range(len(embedded)):
                embedded[i, j] = np.mean(embedded[indices[i, 1:], j])  # skip self (1:)

    denoised_data = embedded[:, 0]
    return denoised_data

# --- 4. Define Error Functions ---
def compute_Edyn(x_clean, x_denoised):
    diff = x_denoised[1:] - x_denoised[:-1]
    return np.sqrt(np.mean(diff**2))

def compute_Etrue(x_clean, x_denoised):
    return np.sqrt(np.mean((x_clean[:len(x_denoised)] - x_denoised)**2))

# --- 5. Iteratively Denoise and Record Errors ---
iterations = 30
E_dyn = []
E_true = []

# Start with noisy data
x_current = x_noisy.copy()

for n in range(1, iterations + 1):
    x_current = schreiber_grassberger_denoising(x_current, iterations=1)  # 1 iteration at a time
    E_dyn.append(compute_Edyn(x_clean, x_current))
    E_true.append(compute_Etrue(x_clean, x_current))

# --- 6. Calculate Ratios for Plotting ---
E_dyn_ratio = E_dyn[0] / np.array(E_dyn)
E_true_ratio = E_true[0] / np.array(E_true)

# --- 7. Plotting ---
fig, axs = plt.subplots(1, 2, figsize=(14, 5))

axs[0].plot(range(1, iterations + 1), E_dyn_ratio)
axs[0].set_xlabel('Iteration number n')
axs[0].set_ylabel(r'$E_{dyn}(1)/E_{dyn}(n)$')
axs[0].set_title('Fig. 3: Edyn(1)/Edyn(n) vs Iteration')

axs[1].plot(range(1, iterations + 1), E_true_ratio)
axs[1].set_xlabel('Iteration number n')
axs[1].set_ylabel(r'$E_{true}(1)/E_{true}(n)$')
axs[1].set_title('Fig. 4: Etrue(1)/Etrue(n) vs Iteration')

plt.tight_layout()
plt.show()

# --- 8. Print Final Ratios ---
print(f"Edyn(1)/Edyn(30) = {E_dyn_ratio[-1]:.2f}")
print(f"Etrue(1)/Etrue(30) = {E_true_ratio[-1]:.2f}")

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def henon_3d(x, y, z, M1, M2, B):
    z_sq = z**2
    if abs(z_sq) > 1e5:  # Increased threshold for case (d)
        return np.nan, np.nan, np.nan
    z_new = M1 + B * x + M2 * y - z_sq
    return y, z, z_new

# Parameter sets from the paper
cases = [
    {"label": "(a) Discrete Lorenz", "B": 0.7, "M1": 0.0, "M2": 0.85},
    {"label": "(b) Discrete Lorenz", "B": 0.7, "M1": 0.0, "M2": 0.815},
    #{"label": "(c) 2D Hénon-like", "B": 0.1, "M1": 1.4, "M2": 0.2},
    #{"label": "(d) Homoclinic", "B": -0.95, "M1": 1.77, "M2": -0.925}
]

# Simulation parameters
n = 20000
transient = 10000
init_conditions = [(0.1, 0.1, 0.1)] * 4

# Special initial condition for case (d)
init_conditions[3] = (0.01, 0.01, 0.01)

# Create figure
fig = plt.figure(figsize=(16, 10))
fig.suptitle("Attractors of the 3D Hénon Map )", fontsize=16)

for i, (case, init) in enumerate(zip(cases, init_conditions)):
    ax = fig.add_subplot(2, 2, i+1, projection='3d')

    # Initialize variables
    x, y, z = init
    X, Y, Z = [], [], []

    # Iterate the map
    for _ in range(n + transient):
        x, y, z = henon_3d(x, y, z, case["M1"], case["M2"], case["B"])
        if _ >= transient:
            if np.any(np.isnan([x, y, z])):
                break
            X.append(x)
            Y.append(y)

            Z.append(z)

    # Plotting
    ax.scatter(X, Y, Z, s=0.1, c=Z, cmap='viridis', alpha=0.6)
    ax.set_title(f'{case["label"]}\nB={case["B"]}, M1={case["M1"]}, M2={case["M2"]}')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.view_init(elev=30, azim=-60)  # Standardize viewing angle

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Parameters for 3D Hénon map
B = 0.1
M1 = 1.4
M2 = 0.2

# Number of iterations
n = 10000

# Arrays to hold x, y, z values
x = np.zeros(n)
y = np.zeros(n)
z = np.zeros(n)

# Initial conditions
x[0], y[0], z[0] = 0.1, 0.1, 0.1

# Iterate the map
for i in range(n - 1):
    x[i + 1] = y[i]
    y[i + 1] = z[i]
    z[i + 1] = M1 + B * x[i] + M2 * y[i] - z[i] ** 2

# Add Gaussian noise to simulate "noisy" version
noise_level = 0.01
x_noisy = x + np.random.normal(0, noise_level, n)
y_noisy = y + np.random.normal(0, noise_level, n)
z_noisy = z + np.random.normal(0, noise_level, n)

# Plotting
fig = plt.figure(figsize=(10, 6))

# Noisy 3D plot
ax1 = fig.add_subplot(121, projection='3d')
ax1.plot(x_noisy, y_noisy, z_noisy, '.', markersize=1, color='gray')
ax1.set_title("Noisy 3D Hénon-like Attractor")
ax1.set_xlabel("x")
ax1.set_ylabel("y")
ax1.set_zlabel("z")

# Clean 3D plot
ax2 = fig.add_subplot(122, projection='3d')
ax2.plot(x, y, z, '.', markersize=1, color='red')
ax2.set_title("Clean 3D Hénon-like Attractor")
ax2.set_xlabel("x")
ax2.set_ylabel("y")
ax2.set_zlabel("z")

plt.tight_layout()
plt.show()